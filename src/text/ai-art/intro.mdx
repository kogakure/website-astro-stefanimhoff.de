In the fall of 2022, I began using [Stable Diffusion](https://stability.ai/stable-diffusion). Initially, I used the amazing iPad OS app [Draw Things](https://drawthings.ai/). When I purchased a new Mac mini M2 Pro in the spring of 2023, I started using the [Stable Diffusion Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui). I experimented with text-to-image and image-to-image generation, inpainting, upscalers, and over 100&nbsp;GB of different [diffusion models](https://civitai.com/). I also experimented with [ControlNet](https://github.com/lllyasviel/ControlNet) and [LoRA](https://huggingface.co/blog/lora). In May 2023, I created my first custom diffusion model in [DreamBooth](https://dreambooth.github.io/) by using 19 images of myself to train a model with my face. Today, I use all kinds of models to create art, including [Gemini 3 Pro](https://deepmind.google/models/gemini/pro/), [GPT-Image 1.5](https://openai.com/de-DE/index/new-chatgpt-images-is-here/), and [FLUX](https://bfl.ai/models).
